# Road map
- Set up a cloud Kubernetes cluster (GKE, EKS, AKS)
- Install Apache Kafka on the Kubernetes cluster
- Install Apache Flink on the Kubernetes cluster
- Design a data processing pipeline using Kafka and Flink
- Use Apache Iceberg for data storage
- Implement data processing logic with Flink applications
- Test and validate the data processing pipeline
- Document the project
- Use public datasets or generate synthetic data for processing
- For open-source data:
- Data source (kaggle , Gouglecloud Dataset,Aws public Data set, Apache NIfi0

### Week 1: Infrastructure Setup
- Kubernetes cluster (GKE, EKS, AKS)
- Apache Kafka
- Apache Flink

## Week 2: Data Processing Design and Implementation
- Kafka
- Flink
- Apache Iceberg

## Week 3: Testing, Validation, and Documentation
- Kafka
- Flink

## Week 4: Data and Kafka Certification Preparation
- Public datasets or synthetic data (Kaggle, Google Cloud Public Datasets, AWS Public Datasets, Apache NiFi)
- Kafka Certification
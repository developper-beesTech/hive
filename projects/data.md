- Set up a cloud Kubernetes cluster (GKE, EKS, AKS)
- Install Apache Kafka on the Kubernetes cluster
- Install Apache Flink on the Kubernetes cluster
- Design a data processing pipeline using Kafka and Flink
- Use Apache Iceberg for data storage
- Implement data processing logic with Flink applications
- Test and validate the data processing pipeline
- Document the project
- Use public datasets or generate synthetic data for processing
- For open-source data:
- Data source (kaggle , Gouglecloud Dataset,Aws public Data set, Apache NIfi0